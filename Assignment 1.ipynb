{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Notes: \n",
    "* Answer each question in a separate Jupynet Notebook Cell\n",
    "* Pleas keep the code in your cells short. \n",
    "  * In notebook programming cells are typicaly short to facilitate reading. \n",
    "  * If well toughout, most answers in this assignment won're require more than 3 or 4 lines of code. \n",
    "* Do no change the list of import, i.e., do not add additional libraries. Those included are the only ones you are allowed to use.\n",
    "* Add your first and Last name below:\n",
    "\n",
    "<Firt Name> <Last Name>\n",
    "    \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "from itertools import product\r\n",
    "from collections import Counter\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this assignment you will be working with Corona Virus (SARS-CoV2) data that was obtained from the [National Center for Biotechnology Information](https://www.ncbi.nlm.nih.gov/). You will need two files. The first (`data/coronavirus_info.csv`) is small and is provided in the GitHub Repo. The second  (`data_report.jsonl`) is larger so you will need to download a compressed version, which you will need to uncompress prior to using. You can downlod the second file here:\r\n",
    "\r\n",
    "https://www.dropbox.com/s/qdn67rshygz06ff/data_report.jsonl.gz?dl=0\r\n",
    "\r\n",
    "We start by loading `data/coronavirus_info.csv` (Code provided below)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# CODE PROVIDED -- DO NOT REMOVE\r\n",
    "table = pd.read_csv(\"data/coronavirus_info.csv\", low_memory=False)\r\n",
    "table = table.drop([\"US State\", \"Host Name\", \"Host Taxonomy ID\", \"Sequence Type\", \"Species Taxonomy Id\", \"Nuc Completeness\", \"BioProject\", \"BioSample\"], axis=1)\r\n",
    "\r\n",
    "missing = table[\"Geo Location\"].isnull()\r\n",
    "table.loc[missing, \"Geo Location\"] = \"\"\r\n",
    "\r\n",
    "\r\n",
    "table.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nucleotide Accession</th>\n",
       "      <th>Species Name</th>\n",
       "      <th>Virus Genus</th>\n",
       "      <th>Virus Family</th>\n",
       "      <th>Isolate Name</th>\n",
       "      <th>Nucleotide Length</th>\n",
       "      <th>Geo Location</th>\n",
       "      <th>Collection Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>Wuhan-Hu-1</td>\n",
       "      <td>29903</td>\n",
       "      <td>Asia; China</td>\n",
       "      <td>2019-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK058807.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04825/2021</td>\n",
       "      <td>29801</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK058777.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04790/2021</td>\n",
       "      <td>29771</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK058695.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04700/2021</td>\n",
       "      <td>29820</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK058662.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04651/2021</td>\n",
       "      <td>29798</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OK058592.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04499/2021</td>\n",
       "      <td>29802</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OK056996.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/FL-CDC-QDX27934346/2021</td>\n",
       "      <td>29775</td>\n",
       "      <td>North America; USA: Florida</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OK056909.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/CA-CDC-QDX27909662/2021</td>\n",
       "      <td>29775</td>\n",
       "      <td>North America; USA: California</td>\n",
       "      <td>2021-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OK056850.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/FL-CDC-QDX27934406/2021</td>\n",
       "      <td>29763</td>\n",
       "      <td>North America; USA: Florida</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OK056784.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/NY-CDC-QDX28007789/2021</td>\n",
       "      <td>29775</td>\n",
       "      <td>North America; USA: New York</td>\n",
       "      <td>2021-08-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nucleotide Accession                                     Species Name  \\\n",
       "0          NC_045512.2  Severe acute respiratory syndrome coronavirus 2   \n",
       "1           OK058807.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "2           OK058777.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "3           OK058695.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "4           OK058662.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "5           OK058592.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "6           OK056996.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "7           OK056909.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "8           OK056850.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "9           OK056784.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "\n",
       "       Virus Genus   Virus Family  \\\n",
       "0  Betacoronavirus  Coronaviridae   \n",
       "1  Betacoronavirus  Coronaviridae   \n",
       "2  Betacoronavirus  Coronaviridae   \n",
       "3  Betacoronavirus  Coronaviridae   \n",
       "4  Betacoronavirus  Coronaviridae   \n",
       "5  Betacoronavirus  Coronaviridae   \n",
       "6  Betacoronavirus  Coronaviridae   \n",
       "7  Betacoronavirus  Coronaviridae   \n",
       "8  Betacoronavirus  Coronaviridae   \n",
       "9  Betacoronavirus  Coronaviridae   \n",
       "\n",
       "                                   Isolate Name  Nucleotide Length  \\\n",
       "0                                    Wuhan-Hu-1              29903   \n",
       "1     SARS-CoV-2/human/USA/MA-MASPHL-04825/2021              29801   \n",
       "2     SARS-CoV-2/human/USA/MA-MASPHL-04790/2021              29771   \n",
       "3     SARS-CoV-2/human/USA/MA-MASPHL-04700/2021              29820   \n",
       "4     SARS-CoV-2/human/USA/MA-MASPHL-04651/2021              29798   \n",
       "5     SARS-CoV-2/human/USA/MA-MASPHL-04499/2021              29802   \n",
       "6  SARS-CoV-2/human/USA/FL-CDC-QDX27934346/2021              29775   \n",
       "7  SARS-CoV-2/human/USA/CA-CDC-QDX27909662/2021              29775   \n",
       "8  SARS-CoV-2/human/USA/FL-CDC-QDX27934406/2021              29763   \n",
       "9  SARS-CoV-2/human/USA/NY-CDC-QDX28007789/2021              29775   \n",
       "\n",
       "                     Geo Location Collection Date  \n",
       "0                     Asia; China         2019-12  \n",
       "1              North America; USA      2021-07-29  \n",
       "2              North America; USA      2021-08-10  \n",
       "3              North America; USA      2021-08-15  \n",
       "4              North America; USA      2021-08-09  \n",
       "5              North America; USA      2021-07-26  \n",
       "6     North America; USA: Florida      2021-08-18  \n",
       "7  North America; USA: California      2021-08-16  \n",
       "8     North America; USA: Florida      2021-08-18  \n",
       "9    North America; USA: New York      2021-08-21  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.1\r\n",
    "\r\n",
    "* The location of each of the sequences is recorded under the `Geo Location` column.  How many entries are from Asia?\r\n",
    "  * Note that for some records, the `Geo Location` column is missing\r\n",
    "  * Display the results using the following format: \r\n",
    "    Asia: XXXX,\r\n",
    "    North America': XXXX,\r\n",
    "    Europe: XXXX,\r\n",
    "    Oceania: XXXX,\r\n",
    "    Africa: XXXX,\r\n",
    "    South America: XXXX \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Write your code here\r\n",
    "output = []\r\n",
    "print(f'Asia: {table[\"Geo Location\"][table[\"Geo Location\"].str.contains(\"Asia\")].count()}')\r\n",
    "counts = table[\"Geo Location\"].str.extract(r'(.*);.*')[0].value_counts()\r\n",
    "for loc in counts.keys():\r\n",
    "    output.append(f'{loc}: {counts[loc]}')\r\n",
    "\r\n",
    "print(', '.join(output))\r\n",
    "\r\n",
    "table"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Asia: 3903\n",
      "North America: 224014, Europe: 189100, Oceania: 10301, Asia: 3903, Africa: 1405, South America: 534\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nucleotide Accession</th>\n",
       "      <th>Species Name</th>\n",
       "      <th>Virus Genus</th>\n",
       "      <th>Virus Family</th>\n",
       "      <th>Isolate Name</th>\n",
       "      <th>Nucleotide Length</th>\n",
       "      <th>Geo Location</th>\n",
       "      <th>Collection Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>Wuhan-Hu-1</td>\n",
       "      <td>29903</td>\n",
       "      <td>Asia; China</td>\n",
       "      <td>2019-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK058807.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04825/2021</td>\n",
       "      <td>29801</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK058777.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04790/2021</td>\n",
       "      <td>29771</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK058695.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04700/2021</td>\n",
       "      <td>29820</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK058662.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>SARS-CoV-2/human/USA/MA-MASPHL-04651/2021</td>\n",
       "      <td>29798</td>\n",
       "      <td>North America; USA</td>\n",
       "      <td>2021-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429318</th>\n",
       "      <td>HG996822.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>a925</td>\n",
       "      <td>29903</td>\n",
       "      <td>Europe; United Kingdom:Oxford</td>\n",
       "      <td>2020-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429319</th>\n",
       "      <td>HG996820.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>a935</td>\n",
       "      <td>29903</td>\n",
       "      <td>Europe; United Kingdom:Oxford</td>\n",
       "      <td>2020-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429320</th>\n",
       "      <td>HG996813.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>a929</td>\n",
       "      <td>29903</td>\n",
       "      <td>Europe; United Kingdom:Oxford</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429321</th>\n",
       "      <td>HG996715.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>a850</td>\n",
       "      <td>29897</td>\n",
       "      <td>Europe; United Kingdom:Oxford</td>\n",
       "      <td>2020-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429322</th>\n",
       "      <td>FR988029.1</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>Betacoronavirus</td>\n",
       "      <td>Coronaviridae</td>\n",
       "      <td>a1290</td>\n",
       "      <td>29897</td>\n",
       "      <td>Europe; United Kingdom:Oxford</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429323 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nucleotide Accession                                     Species Name  \\\n",
       "0               NC_045512.2  Severe acute respiratory syndrome coronavirus 2   \n",
       "1                OK058807.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "2                OK058777.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "3                OK058695.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "4                OK058662.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "...                     ...                                              ...   \n",
       "429318           HG996822.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "429319           HG996820.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "429320           HG996813.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "429321           HG996715.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "429322           FR988029.1  Severe acute respiratory syndrome coronavirus 2   \n",
       "\n",
       "            Virus Genus   Virus Family  \\\n",
       "0       Betacoronavirus  Coronaviridae   \n",
       "1       Betacoronavirus  Coronaviridae   \n",
       "2       Betacoronavirus  Coronaviridae   \n",
       "3       Betacoronavirus  Coronaviridae   \n",
       "4       Betacoronavirus  Coronaviridae   \n",
       "...                 ...            ...   \n",
       "429318  Betacoronavirus  Coronaviridae   \n",
       "429319  Betacoronavirus  Coronaviridae   \n",
       "429320  Betacoronavirus  Coronaviridae   \n",
       "429321  Betacoronavirus  Coronaviridae   \n",
       "429322  Betacoronavirus  Coronaviridae   \n",
       "\n",
       "                                     Isolate Name  Nucleotide Length  \\\n",
       "0                                      Wuhan-Hu-1              29903   \n",
       "1       SARS-CoV-2/human/USA/MA-MASPHL-04825/2021              29801   \n",
       "2       SARS-CoV-2/human/USA/MA-MASPHL-04790/2021              29771   \n",
       "3       SARS-CoV-2/human/USA/MA-MASPHL-04700/2021              29820   \n",
       "4       SARS-CoV-2/human/USA/MA-MASPHL-04651/2021              29798   \n",
       "...                                           ...                ...   \n",
       "429318                                       a925              29903   \n",
       "429319                                       a935              29903   \n",
       "429320                                       a929              29903   \n",
       "429321                                       a850              29897   \n",
       "429322                                      a1290              29897   \n",
       "\n",
       "                         Geo Location Collection Date  \n",
       "0                         Asia; China         2019-12  \n",
       "1                  North America; USA      2021-07-29  \n",
       "2                  North America; USA      2021-08-10  \n",
       "3                  North America; USA      2021-08-15  \n",
       "4                  North America; USA      2021-08-09  \n",
       "...                               ...             ...  \n",
       "429318  Europe; United Kingdom:Oxford      2020-11-27  \n",
       "429319  Europe; United Kingdom:Oxford      2020-12-10  \n",
       "429320  Europe; United Kingdom:Oxford      2020-12-01  \n",
       "429321  Europe; United Kingdom:Oxford      2020-11-29  \n",
       "429322  Europe; United Kingdom:Oxford             NaN  \n",
       "\n",
       "[429323 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.2\n",
    "Use the `coronavirus_info.csv` table to count the entries that are from Hawaii. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Write your code here\r\n",
    "print(f'Hawaii: {table[\"Geo Location\"][table[\"Geo Location\"].str.contains(\"Hawaii\")].count()}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hawaii: 119\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.3\r\n",
    "\r\n",
    "The file `data_report.jsonl` contains the variants of the virus in the DB. This `json` file is a list of records (one per line) for each one of the genomes in the database. Before we work with the large file, we will experiment with a file containing a single record.\r\n",
    "\r\n",
    "The file `single_record.json` contains a single sample record. Use the `JSON library to load the file `single_record.json` into a variable called `sample_vir_record`\r\n",
    "\r\n",
    "1. how many first-level keys does this record have?\r\n",
    "  * Do not count nested keys. Only those at the top level should be counted\r\n",
    "  * **There are 18 first-level keys.**\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Write your code here\r\n",
    "import json\r\n",
    "\r\n",
    "file = open('data/single_record.json')\r\n",
    "sample_vir_record = json.load(file)\r\n",
    "print(len(sample_vir_record.keys()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.4\n",
    "\n",
    "Each Covid various in this database is classified according to a system referred to as the Pangolin (Phylogenetic Assignment of Named Global Outbreak LINeages) classification. It is not essential to complete the assignment that you understand this system, but if you're interested in learning more, see:\n",
    "\n",
    "https://cov-lineages.org/resources/pangolin.html\n",
    "\n",
    "The Pangolin classification of this sample record is nested within the `virus` key:\n",
    "```json\n",
    "{ ...\n",
    "  \"virus\": {\n",
    "              ...\n",
    "              \"pangolinClassification\": \n",
    "              ...\n",
    "            }\n",
    "  ... \n",
    "}\n",
    "```\n",
    "Write code to extract the classification of this record. The result should be `B.1.1.214`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Write your code here\r\n",
    "print(sample_vir_record[\"virus\"][\"pangolinClassification\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "B.1.1.214\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We hear in the news about `Alpha`, `Beta`, `Delta` variants of concern and recently the Mu variant as being of interest. Basedon your answer to `Q.3`, you may have been tempted to infer that this virus is of type `Beta` since the first letter is `B`. In fact, this variant of type `Alpha` and is a variant of concern. Although not relevant to this exercise, the rules for naming new variants and the list of known `SARS-CoV-2` are provided here:\n",
    "\n",
    "https://www.pango.network/how-does-the-system-work/what-are-pango-lineages/\n",
    "\n",
    "https://cov-lineages.org/lineage_list.html\n",
    "\n",
    "\n",
    "The following short video is very helpful for understanding what a variant is, how it arises, how it's named, and why some variants are more concerning than others.\n",
    "\n",
    "https://www.youtube.com/watch?v=B8UEZ9cfgz4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.5\r\n",
    "\r\n",
    "Write Python code that counts all the different kinds of variants in `data_report.jsonl`. \r\n",
    "Because the file is 7GB, you won't likely be able to load it into your laptop's RAM using Python. I encountered this error when trying to open it on my laptop\r\n",
    "\r\n",
    "![](https://www.dropbox.com/s/lieo685pafkgm5e/ram_error.png?dl=1)\r\n",
    "\r\n",
    "\r\n",
    "It would be easy to extract the data from the pangolinClassification field of each `json` record by reading each line (a record) at a time.\r\n",
    "\r\n",
    "The list of current variants of concern we are interested in are:\r\n",
    "* Alpha (B.1.1.7)\r\n",
    "* Beta (B.1.351, B.1.351.2, B.1.351.3)\r\n",
    "* Delta (B.1.617.2, AY.1, AY.2, AY.3)\r\n",
    "* Gamma (P.1, P.1.1, P.1.2) \r\n",
    "\r\n",
    "You should get something similar to what follows:\r\n",
    "```\r\n",
    "Alpha: X\r\n",
    "Beta: X\r\n",
    "Delta: X\r\n",
    "Gamma: X\r\n",
    "```\r\n",
    "Where `X` represents the counts for relevant variants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Write your code here\r\n",
    "counter = [0, 0, 0, 0]\r\n",
    "concerns = {\"B.1.1.7\": 0, \"B.1.351\": 1, \"B.1.351.2\": 1, \"B.1.351.3\": 1, \"B.1.617.2\": 2, \"AY.1\": 2, \"AY.2\": 2, \"AY.3\": 2, \"P.1\": 3, \"P.1.1\": 3, \"P.1.2\": 3}\r\n",
    "\r\n",
    "with open('data/data_report.jsonl') as reader:\r\n",
    "    for line in reader:\r\n",
    "        jsonLine = json.loads(line)\r\n",
    "        try:\r\n",
    "            counter[concerns[jsonLine[\"virus\"][\"pangolinClassification\"]]] += 1\r\n",
    "        except KeyError:\r\n",
    "            continue\r\n",
    "\r\n",
    "print(f'Alpha: {counter[0]}, Beta: {counter[1]}, Delta: {counter[2]}, Gamma: {counter[3]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alpha: 178423, Beta: 584, Delta: 4392, Gamma: 6632\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find similar viruses.\n",
    "\n",
    "It's often useful to compare viruses to study how similar strains are. While sophisticated algorithms to compare a pair of viruses exist, these are typically computationally intensive and cannot be used to carry out a large number of comparisons. \n",
    "\n",
    "An alternative, albeit less sensitive, approach consists of comparing word counts (called k-mers, where k is the word size) across genomes.  Suppose we have two viruses X and Y, with the following Genomes.\n",
    "```\n",
    "X = \"ACGTAGTGCATGTGTAGCTGTGTAGCTGTAC\"\n",
    "Y = \"ACTAGTGCATGTGTAGCTCTGTAGCTGATAC\"\n",
    "```\n",
    "\n",
    "To compare `X` and `Y`, we first vectorize these genomes by marking the presence of words (k-mers) as a boolean value, 0 if absent and 1 if the word is present. This method assumes that similar genomes will have the same words, which makes sense.\n",
    "\n",
    "This idea, which is referred to as the bag of words model is computationally efficient, making it ideal to vectorize text in big data analytics. Another variant of this model requires replacing the presence and absence by counts for each word.\n",
    "\n",
    "The code below vectorizes an input DNA sequence intro k-mers of size k=2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# CODE PROVIDED -- DO NOT REMOVE\r\n",
    "def get_kmer_2(X):\r\n",
    "    DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "    words_size_2 = [\"\".join(dna_prod) for dna_prod in product(DNA, DNA)]\r\n",
    "    counts = pd.Series([0 for _ in words_size_2], index = words_size_2)\r\n",
    "    words_in_X = set([X[i:i+2] for i in range(0, len(X)-1)])\r\n",
    "    counts[list(words_in_X)] = 1\r\n",
    "    return counts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# CODE PROVIDED -- DO NOT REMOVE\r\n",
    "# X has 3 words of size 2 (AC, CG, GT)\r\n",
    "X = \"ACGT\"\r\n",
    "get_kmer_2(\"ACGT\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AA    0\n",
       "AC    1\n",
       "AG    0\n",
       "AT    0\n",
       "CA    0\n",
       "CC    0\n",
       "CG    1\n",
       "CT    0\n",
       "GA    0\n",
       "GC    0\n",
       "GG    0\n",
       "GT    1\n",
       "TA    0\n",
       "TC    0\n",
       "TG    0\n",
       "TT    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function below takes a dictionary of sequences' counts as a `pandas Series` and prints it using HTML Table, which you might agree is nicer to visualize."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# CODE PROVIDED -- DO NOT REMOVE\r\n",
    "def pretty_print_counts(counts_dict):\r\n",
    "    list_of_count = [data.to_list() for data in counts_dict.values()]\r\n",
    "    list_of_indices = [x for x in counts_dict.keys()]\r\n",
    "    list_of_columns = list(counts_dict.values())[0].index.to_list()\r\n",
    "    df_single_level_cols = pd.DataFrame(list_of_count,\r\n",
    "                                        index=[x for x in counts_dict.keys()],\r\n",
    "                                       columns = list_of_columns)    \r\n",
    "    return df_single_level_cols \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# CODE PROVIDED -- DO NOT REMOVE\r\n",
    "\r\n",
    "X = \"ACGTACGTACGTACGT\"\r\n",
    "Y = \"ACGTACAAACGTACGT\"\r\n",
    "Z = \"TTTTACAAACGTTTTT\"\r\n",
    "\r\n",
    "counts_dict = {\"X\": get_kmer_2(X), \"Y\": get_kmer_2(Y), \"Z\": get_kmer_2(Z)}\r\n",
    "pretty_print_counts(counts_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT\n",
       "X   0   1   0   0   0   0   1   0   0   0   0   1   1   0   0   0\n",
       "Y   1   1   0   0   1   0   1   0   0   0   0   1   1   0   0   0\n",
       "Z   1   1   0   0   1   0   1   0   0   0   0   1   1   0   0   1"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.6\r\n",
    "\r\n",
    "Write a function that computes the Jaccard similarity between two feature vectors, A and B. If you recall, Jaccard similarity is computed as:\r\n",
    "\r\n",
    "$$J(A,B) = \\frac{A \\cap B}{A \\cup B}$$\r\n",
    "\r\n",
    "In other words, the number of items shared by `A` and `B` over the set of all items in `A` or `B`.\r\n",
    "\r\n",
    "For example, for `A= get_kmer_2(X)` and B = get_kmer_2(Y) above,\r\n",
    "\r\n",
    "$$\r\n",
    "J(A,B) = \\frac{4}{6}\r\n",
    "$$\r\n",
    "\r\n",
    "Your function should have the following signature: \r\n",
    "\r\n",
    "`jaccard(A, B)`\r\n",
    "\r\n",
    "Where `A` and `B` are `pandas Series`\r\n",
    "\r\n",
    "\r\n",
    "Test your function using the code below to make sure it's correct."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Write you code here\r\n",
    "def jaccard(A, B):\r\n",
    "    similar = sum(A & B)\r\n",
    "    total = sum(A | B)\r\n",
    "    return similar / total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# TEST PROVIDED -- DO NOT REMOVE\r\n",
    "A = get_kmer_2(X)\r\n",
    "B = get_kmer_2(Y)\r\n",
    "assert jaccard(A, B) == 4/6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.7 \n",
    "\n",
    "* Compute the jaccard similarity for the pairs of sequences `(X, Y)`, `(X, Z)`, `(Y, Z)`. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Write you code here\r\n",
    "X = \"ACGTACGTACGTACGT\"\r\n",
    "Y = \"ACGTACAAACGTACGT\"\r\n",
    "Z = \"TTTTACAAACGTTTTT\"\r\n",
    "\r\n",
    "A = get_kmer_2(X)\r\n",
    "B = get_kmer_2(Y)\r\n",
    "C = get_kmer_2(Z)\r\n",
    "\r\n",
    "print(f\"pair (X, Y): {jaccard(A, B)}\")\r\n",
    "print(f\"pair (X, Z): {jaccard(A, C)}\")\r\n",
    "print(f\"pair (Y, Z): {jaccard(B, C)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pair (X, Y): 0.6666666666666666\n",
      "pair (X, Z): 0.5714285714285714\n",
      "pair (Y, Z): 0.8571428571428571\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.8\n",
    "\n",
    "The vectors representing the presence and absence of words in both `Y` and `Z` are very similar (Jaccard = 0.85), despite major differences at the DNA level between these two sequences. This is because the words are small -- it is as if you were comparing a history book with a book on Python using words of size 2. It's very likely that both books will contain the same words of size 2. Increasing the size of `k` will produce substantial differences. \n",
    "\n",
    "Change the function `get_kmer_2` so that given a sequence `X` and a k-mer size `k`, the function returns a boolean vector of all the words of size `k` in `X`. Cal the function `get_kmer`\n",
    "\n",
    "\n",
    "\n",
    "The following code can be used to generate all DNA words of size `k`\n",
    "```pyton\n",
    "words_size_k = [\"\".join(prod) for prod in product(*([DNA]*k))]\n",
    "```\n",
    "\n",
    "Once done, use the code below to test your function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Write you code here\r\n",
    "def get_kmer(X, k):\r\n",
    "    DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "    words_size_k = [\"\".join(dna_prod) for dna_prod in product(DNA, repeat=k)]\r\n",
    "    counts = pd.Series([0 for _ in words_size_k], index = words_size_k)\r\n",
    "    words_in_X = set([X[i:i+k] for i in range(0, len(X)-(k-1))])\r\n",
    "    counts[list(words_in_X)] = 1\r\n",
    "    return counts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# TEST PROVIDED -- DO NOT REMOVE\r\n",
    "X = \"ACGTGATGATTG\"\r\n",
    "\r\n",
    "counts = get_kmer(X, k=1)\r\n",
    "assert counts.tolist() == [1,1,1,1]\r\n",
    "\r\n",
    "\r\n",
    "counts = get_kmer(X, k=3)\r\n",
    "assert (counts[[\"ACG\", \"CGT\", \"GTG\", \"TGA\", \"GAT\", \"ATG\", \"ATT\", \"TTG\"]] == 1).sum()  == 8\r\n",
    "assert (counts.drop([\"ACG\", \"CGT\", \"GTG\", \"TGA\", \"GAT\", \"ATG\", \"ATT\", \"TTG\"]) == 0).sum()  == 56\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.9\n",
    "\n",
    "* Compute the Jaccard similarity for the pairs `(X, Y)`, `(X, Z)`, `(Y, Z)` using `k= 5`\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Write you code here\r\n",
    "X = \"ACGTACGTACGTACGT\"\r\n",
    "Y = \"ACGTACAAACGTACGT\"\r\n",
    "Z = \"TTTTACAAACGTTTTT\"\r\n",
    "\r\n",
    "A = get_kmer(X, 5)\r\n",
    "B = get_kmer(Y, 5)\r\n",
    "C = get_kmer(Z, 5)\r\n",
    "\r\n",
    "print(f\"pair (X, Y): {jaccard(A, B)}\")\r\n",
    "print(f\"pair (X, Z): {jaccard(A, C)}\")\r\n",
    "print(f\"pair (Y, Z): {jaccard(B, C)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pair (X, Y): 0.4\n",
      "pair (X, Z): 0.0\n",
      "pair (Y, Z): 0.29411764705882354\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The appropriate word size varies with the length of the text, with larger words depicting similarity more accurately. However, large values of `k` are:\r\n",
    "1. More computationally intensive to compute. With k = 12, there are $4^{12} = 16,777,216$ words to compute for each sequence.\r\n",
    "\r\n",
    "2. More likely to skew the distance between fairly similar sequences. For example `k=8`, the Jaccard index between `X` and `Y` is `0`, even though `X` and `Y` have only two mismatching characters. While this is an extreme case due to the fact that X and Y are short, the logic applies to longer sequences and larger values of `k`\r\n",
    "\r\n",
    "\r\n",
    "![](https://www.dropbox.com/s/rhw5szbiohsqu7w/mismatches.png?dl=1)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Write you code here\r\n",
    "X = \"ACGTACGTACGTACGT\"\r\n",
    "Y = \"ACGTACAAACGTACGT\"\r\n",
    "Z = \"TTTTACAAACGTTTTT\"\r\n",
    "\r\n",
    "A = get_kmer(X, 8)\r\n",
    "B = get_kmer(Y, 8)\r\n",
    "C = get_kmer(Z, 8)\r\n",
    "\r\n",
    "print(f\"pair (X, Y): {jaccard(A, B)}\")\r\n",
    "print(f\"pair (X, Z): {jaccard(A, C)}\")\r\n",
    "print(f\"pair (Y, Z): {jaccard(B, C)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pair (X, Y): 0.08333333333333333\n",
      "pair (X, Z): 0.0\n",
      "pair (Y, Z): 0.125\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After calculating the Jaccard similarity between X and Y with k=8, I find that it is not 0, therefore the second claim above is incorrect."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code I used is provided as a reference below. The code took 7 hours to complete on a single machine and approximately 12 minutes on a larger server with 72 cores and 1TB of RAM. To parallelize the execution, I split the file into files that contain 1000 sequences each and used GNU Parallel to run each file on a single CPU core."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# CODE PROVIDED FOR ILLUTRATION -- DO NOT REMOVE\r\n",
    "# RUNNING LOCALLY MAY TAKE A LONG TIME TO COMPLETE\r\n",
    "\r\n",
    "# k = 8 \r\n",
    "# DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "# words_size_k = [\"\".join(prod) for prod in product(*([DNA]*k))]\r\n",
    "\r\n",
    "    \r\n",
    "# def get_kmer_mod(X):\r\n",
    "#     counts = pd.Series([0 for _ in words_size_k], index = words_size_k)\r\n",
    "#     words_in_X = set([X[i:i+k] for i in range(0, len(X)-k+1)])\r\n",
    "#     counts[list(words_in_X)] = 1\r\n",
    "#     return counts   \r\n",
    "\r\n",
    "# def replace_bad_nucs(seq):\r\n",
    "#     for character in ['W', 'K', \"Y\", \"M\", 'H']:\r\n",
    "#         seq = seq.replace(character, 'A') \r\n",
    "        \r\n",
    "#     for character in ['R', 'S', 'D', \"V\", \"B\"]:\r\n",
    "#         seq = seq.replace(character, 'C') \r\n",
    "        \r\n",
    "#     seq = seq.replace(\"N\", '') \r\n",
    "    \r\n",
    "#     return seq\r\n",
    "\r\n",
    "# all_counts = []\r\n",
    "# all_names = []\r\n",
    "# with tqdm(total=1000) as pbar:\r\n",
    "#     for record in SeqIO.parse(\"myseq0.fa\", 'fasta'):\r\n",
    "#         all_names.append(record.id)\r\n",
    "#         seq = replace_bad_nucs(str(record.seq))\r\n",
    "\r\n",
    "#         counts = get_kmer_mod(seq)\r\n",
    "#         all_counts.append(counts)\r\n",
    "#         pbar.update(1)\r\n",
    "    \r\n",
    "# kmer_counts = pd.DataFrame(all_counts, index = all_names)\r\n",
    "# kmer_counts.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hashing Sequences\r\n",
    "\r\n",
    "We are interested in finding pairs of sequences that are very similar. However, comparing the sequences pairwise is not tractable since it would require carrying out $429282 * (429282 - 1) / 2 = 92,141,303,121$ comparisons.\r\n",
    "\r\n",
    "Instead, we will use the hashing-based approach covered in class. Rather than hashing a sequence over all k-mers, we will only compute the hash for a subset of k-mers. we will repeat the operation n times to avoid that similar sequences are assigned to different bins due to a single, rare mismatch.\r\n",
    "\r\n",
    "This, as discussed in class, is computationally more efficient compared to computing all pairwise sequences. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.10 \r\n",
    "\r\n",
    "Write a function that takes a `pandas  Series` and a subset of columns and returns the hash computed on the subset of columns. Call this function`hash_on_subset`.\r\n",
    "\r\n",
    "As an example, consider all words with a size of 2 as follows \r\n",
    "\r\n",
    "|\t|AA\t|AC\t|AG\t|AT\t|CA | CC| CG| CT| GA| GC| GG| GT| TA| TC| TG| TT|\r\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\r\n",
    "| A\t|0\t|1\t|0\t|0\t|0\t|0\t|1\t|0\t| 0 |0\t|0\t| 1 |1  |0\t|0\t|0  |\r\n",
    "\r\n",
    "```python\r\n",
    "hash_on_subset(A, [\"AC\", \"CG\", \"CT\", \"GT\", \"TA\"]) \r\n",
    "```\r\n",
    "\r\n",
    "is equivalent to:\r\n",
    "\r\n",
    "```python\r\n",
    "hash((1, 1, 0, 1, 1)) == 5085477689562523216\r\n",
    "```\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Write you code here\r\n",
    "def hash_on_subset(X, subset):\r\n",
    "    return hash(tuple([X[word] for word in subset]))\r\n",
    "\r\n",
    "X = \"ACGTACGTACGTACGT\"\r\n",
    "A= get_kmer(X, 2)\r\n",
    "B = pd.Series(X)\r\n",
    "\r\n",
    "counts_dict = {\"X\": get_kmer(X, 2)}\r\n",
    "\r\n",
    "assert hash_on_subset(A, [\"AC\", \"CG\", \"CT\", \"GT\", \"TA\"]) == hash((1, 1, 0, 1, 1))\r\n",
    "\r\n",
    "pretty_print_counts(counts_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT\n",
       "X   0   1   0   0   0   0   1   0   0   0   0   1   1   0   0   0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The method `sample` from the random module `m` words from a list\n",
    "\n",
    "For example, running:\n",
    "```python\n",
    "random.sample( [\"A\", \"C\", \"G\", \"T\"], 2 )\n",
    "```\n",
    "returns\n",
    "```\n",
    "['A', 'C']\n",
    "```\n",
    "The returned subset may be different for you.\n",
    "\n",
    "* The code below randomly selects `m=20` k-mers we will use to compare the genomes\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "random.sample( [\"A\", \"C\", \"G\", \"T\"], 2 )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['T', 'G']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "k=8\r\n",
    "DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "words_size_k = [\"\".join(prod) for prod in product(*([DNA]*k))]\r\n",
    "\r\n",
    "m=20\r\n",
    "subset_kmers = random.sample(words_size_k, m)\r\n",
    "\r\n",
    "# subset_kmers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.12\r\n",
    "\r\n",
    "\r\n",
    "Apply the function `hash_subset` to all the rows of `all_kmers_df`. The data science (*vectorized*) way to do so is using the `apply` method available on a `pandas DataFrame` instead of using for loops. For example, given a DataFrame `df` such that:\r\n",
    "\r\n",
    "```\r\n",
    "df = pd.DataFrame([[1,2,3], [4,5,6]])\r\n",
    "\r\n",
    "```\r\n",
    "then \r\n",
    "```\r\n",
    "df.apply(max, args=[] axis=1)\r\n",
    "```\r\n",
    "applies the `max()` function on each row (`axis = 1`). Here, `args` is empty since `max` does not take any additional arguments.\r\n",
    "\r\n",
    "The example below shows how to use `apply` when the function requires additional arguments. In this example, we apply a function that sums all the values of a row and adds to the sum an offset (2 by default)\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# EXAMPLE CODE PROVIDED -- DO NOT REMOVE\r\n",
    "def add_val_to_sum(x, offset=2):\r\n",
    "    return x.sum() + offset\r\n",
    "    \r\n",
    "df = pd.DataFrame([[1,2,3], [4,5,6]])\r\n",
    "\r\n",
    "print(\"The sum of rows + an offset of 5 is:\")\r\n",
    "print(df.apply(add_val_to_sum, args=[5], axis=1))\r\n",
    "\r\n",
    "print(\"The sum of rows + an offset of 10 is:\")\r\n",
    "print(df.apply(add_val_to_sum, args=[10], axis=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The sum of rows + an offset of 5 is:\n",
      "0    11\n",
      "1    20\n",
      "dtype: int64\n",
      "The sum of rows + an offset of 10 is:\n",
      "0    16\n",
      "1    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "all_kmers_df = pd.read_csv('data/all_kmers_10k.csv', low_memory=False)\r\n",
    "hash_values = all_kmers_df.iloc[: ,1:].apply(hash_on_subset, args=[subset_kmers], axis=1)\r\n",
    "hash_values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      -3787797319238645235\n",
       "1      -3787797319238645235\n",
       "2      -3787797319238645235\n",
       "3      -3787797319238645235\n",
       "4      -3787797319238645235\n",
       "               ...         \n",
       "9983   -3787797319238645235\n",
       "9984   -3787797319238645235\n",
       "9985   -3787797319238645235\n",
       "9986   -3787797319238645235\n",
       "9987   -3787797319238645235\n",
       "Length: 9988, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q.13\r\n",
    "\r\n",
    "\r\n",
    "Use `apply()` to apply `hash_subset` and compute the hash values for all the rows of `all_kmers_df` over `subset_kmers`\r\n",
    "\r\n",
    "* Create a dict by parsing the results to group sequences that yield the same hash under the same bins. Each key in the dict should be a key and each value is a list of sequences that have the same value.\r\n",
    "\r\n",
    "For example, in the dictionary below, X and Y have the same hash value (123456) over a given subset of kmers, whereas Z has a different hash over the same subsets.\r\n",
    "\r\n",
    "```\r\n",
    "{\"123456\": [X,Y], \"654321\": [Z]}\r\n",
    "```\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Write your code here\r\n",
    "all_kmers_df = pd.read_csv('data/all_kmers_10k.csv', low_memory=False)\r\n",
    "\r\n",
    "hash_dict = {}\r\n",
    "\r\n",
    "hash_values = all_kmers_df.iloc[: ,1:].apply(hash_on_subset, args=[subset_kmers], axis=1)\r\n",
    "for i, value in hash_values.items():\r\n",
    "    if value in hash_dict:\r\n",
    "        hash_dict[value].append(all_kmers_df.iloc[i, 0])\r\n",
    "    else:\r\n",
    "        hash_dict[value] = []\r\n",
    "        hash_dict[value].append(all_kmers_df.iloc[i, 0])\r\n",
    "\r\n",
    "for key in hash_dict.keys():\r\n",
    "    print(f\"{key} bin contains {len(hash_dict[key])} sequences\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-3787797319238645235 bin contains 9354 sequences\n",
      "4311678649273552725 bin contains 461 sequences\n",
      "5181165943676010871 bin contains 72 sequences\n",
      "2056828653637597067 bin contains 1 sequences\n",
      "3769039320219435653 bin contains 19 sequences\n",
      "-494279968171068226 bin contains 6 sequences\n",
      "-4358028601095475148 bin contains 24 sequences\n",
      "-7921249390818900437 bin contains 1 sequences\n",
      "-9070949046932304923 bin contains 4 sequences\n",
      "1074885204110590458 bin contains 7 sequences\n",
      "2929769605153875219 bin contains 3 sequences\n",
      "-4155950262683392094 bin contains 3 sequences\n",
      "3068673559513927815 bin contains 1 sequences\n",
      "4755555667116831713 bin contains 10 sequences\n",
      "3524604605240784921 bin contains 4 sequences\n",
      "-2885931845027787659 bin contains 1 sequences\n",
      "3271126087547661102 bin contains 3 sequences\n",
      "5366043112465369106 bin contains 5 sequences\n",
      "-7627424668334000466 bin contains 2 sequences\n",
      "19374587003978416 bin contains 2 sequences\n",
      "5761912339081102800 bin contains 2 sequences\n",
      "-5783337471323114861 bin contains 1 sequences\n",
      "9014525465465541514 bin contains 1 sequences\n",
      "6965086233202075448 bin contains 1 sequences\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q. 15\n",
    "\n",
    "Here we use the presence and absence of words, i.e., a vector of booleans, to encode a sequence. The problem with this approach is that it considers the sequences to be identical, even if their word counts differ substantially. For example, given the sequence `X`, `Y` and `Z` as follows\n",
    "```\n",
    "X = ATAGATAGATAGATAGATT\n",
    "Y = ATAGATAGATAGATAGATT\n",
    "Z = ATAGATTTTTTTTTTTTTT\n",
    "```\n",
    "With k =2, all three sequences mach on their vector of word presence/absense."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X = \"ATAGATAGATAGATAGATT\"\r\n",
    "Y = \"ATAGATAGATAGATAGATT\"\r\n",
    "Z = \"ATAGATTTTTTTTTTTTTT\"\r\n",
    "\r\n",
    "counts_dict = {\"X\": get_kmer(X, k=2), \"Y\": get_kmer(Y, k=2), \"Z\": get_kmer(Z, k=2)}\r\n",
    "pretty_print_counts(counts_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT\n",
       "X   0   0   1   1   0   0   0   0   1   0   0   0   1   0   0   1\n",
       "Y   0   0   1   1   0   0   0   0   1   0   0   0   1   0   0   1\n",
       "Z   0   0   1   1   0   0   0   0   1   0   0   0   1   0   0   1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Comparing these sequences based on word counts, X is much more similar to Y than it is to Z"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_kmer_counts(X, k):\r\n",
    "    DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "    words_size_k = [\"\".join(prod) for prod in product(*([DNA]*k))]\r\n",
    "    counts = pd.Series([0 for _ in words_size_k], index = words_size_k)\r\n",
    "    counts_words_in_x = Counter([X[i:i+k] for i in range(0, len(X)-k+1)])\r\n",
    "    counts.update(counts_words_in_x)\r\n",
    "    return counts    \r\n",
    "\r\n",
    "\r\n",
    "counts_dict = {\"X\": get_kmer_counts(X, k=2), \"Y\": get_kmer_counts(Y, k=2), \"Z\": get_kmer_counts(Z, k=2)}\r\n",
    "pretty_print_counts(counts_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT\n",
       "X   0   0   4   5   0   0   0   0   4   0   0   0   4   0   0   1\n",
       "Y   0   0   4   5   0   0   0   0   4   0   0   0   4   0   0   1\n",
       "Z   0   0   1   2   0   0   0   0   1   0   0   0   1   0   0  13"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Given an example (vectors) to justify why hashing is not ideal with counts.\r\n",
    "  * Use any means you think are useful to illustrate your point (e.g.: figure, simulation (yes, please!))\r\n",
    " \r\n",
    "* Describe how the random project approach discussed in class can help solve the issue discussed\r\n",
    "  * Use code to illustrate how random projection works in the following example.\r\n",
    "    * I.e., provide code to provide an example where `X` and `Y` are assigned to the same bin and `Z` is assigned to a different bin.\r\n",
    "    * You can choose any vector values as needed \r\n",
    " \r\n",
    "```python\r\n",
    "X = [1,2]\r\n",
    "Y = [2,2]\r\n",
    "Z = [5,1]\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X = \"ATAGATAGATAGATAGATT\"\r\n",
    "Y = \"ATAGATAGATAGATAGATA\"\r\n",
    "Z = \"ATAGATTTTTTTTTTTTTT\"\r\n",
    "\r\n",
    "DNA = [\"A\", \"C\", \"G\", \"T\"]\r\n",
    "words_size_2 = [\"\".join(prod) for prod in product(*([DNA]*2))]\r\n",
    "\r\n",
    "A = get_kmer_counts(X, k=2)\r\n",
    "B = get_kmer_counts(Y, k=2)\r\n",
    "C = get_kmer_counts(Z, k=2)\r\n",
    "counts_dict = {\"X\": A, \"Y\": B, \"Z\": C}\r\n",
    "\r\n",
    "print(f\"Hash of seq X: {hash_on_subset(A, words_size_2)}\")\r\n",
    "print(f\"Hash of seq Y: {hash_on_subset(B, words_size_2)}\")\r\n",
    "print(f\"Hash of seq Z: {hash_on_subset(C, words_size_2)}\")\r\n",
    "\r\n",
    "pretty_print_counts(counts_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hash of seq X: -5501209074414000334\n",
      "Hash of seq Y: -3803320541289006980\n",
      "Hash of seq Z: -5847270639451158862\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>AC</th>\n",
       "      <th>AG</th>\n",
       "      <th>AT</th>\n",
       "      <th>CA</th>\n",
       "      <th>CC</th>\n",
       "      <th>CG</th>\n",
       "      <th>CT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GC</th>\n",
       "      <th>GG</th>\n",
       "      <th>GT</th>\n",
       "      <th>TA</th>\n",
       "      <th>TC</th>\n",
       "      <th>TG</th>\n",
       "      <th>TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA  AC  AG  AT  CA  CC  CG  CT  GA  GC  GG  GT  TA  TC  TG  TT\n",
       "X   0   0   4   5   0   0   0   0   4   0   0   0   4   0   0   1\n",
       "Y   0   0   4   5   0   0   0   0   4   0   0   0   5   0   0   0\n",
       "Z   0   0   1   2   0   0   0   0   1   0   0   0   1   0   0  13"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hashing might not be ideal with counts because as we can see in the above example, even though sequence X and Y are extremely similar (only off by one base). They were placed in different bins when we hashed by kmers counts. \r\n",
    "\r\n",
    "A solution to this issue can be solved using random projection, since random projection projects the vectors onto a randomly selected vector and is binned based on how far those vectors is from the randomly selected vector.\r\n",
    "This helps solve the issue above because if we look at the above counts the X vector and the Y vector are very similar therefore their distance from a randomly selected vector will most likely be similar as well, thus random projection will bin them into the same bin unlike what happens with hashing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "### Write your code here\r\n",
    "\r\n",
    "### Projection as a Dot Product\r\n",
    "\r\n",
    "X = [1,2]\r\n",
    "Y = [2,2]\r\n",
    "Z = [5,1]\r\n",
    "\r\n",
    "A = [1, 1]\r\n",
    "\r\n",
    "amp_A = (A[0]**2 + A[1]**2)**0.5\r\n",
    "\r\n",
    "X_dot_A = X[0]*A[0] + X[1]*A[1]\r\n",
    "proj_X = X_dot_A / amp_A\r\n",
    "\r\n",
    "print(f\"Projection of X occurs in bin {int((proj_X / amp_A)) + ((proj_X % amp_A) != 0)}\")\r\n",
    "\r\n",
    "Y_dot_A = Y[0]*A[0] + Y[1]*A[1]\r\n",
    "proj_Y = Y_dot_A / amp_A\r\n",
    "\r\n",
    "print(f\"Projection of Y occurs in bin {int((proj_Y / amp_A)) + ((proj_Y % amp_A) != 0)}\")\r\n",
    "\r\n",
    "Z_dot_A = Z[0]*A[0] + Z[1]*A[1]\r\n",
    "proj_Z = Z_dot_A / amp_A\r\n",
    "\r\n",
    "print(f\"Projection of Z occurs in bin {int((proj_Z / amp_A)) + ((proj_Z % amp_A) != 0)}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Projection of X occurs in bin 2\n",
      "Projection of Y occurs in bin 2\n",
      "Projection of Z occurs in bin 3\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('myenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "caef97c8722a1a979d56425057a5b5a27c52a0679a3677a767a4268ae9a6b904"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}